<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Voice Beat Maker</title>
  <script src="https://cdn.jsdelivr.net/npm/tone@14.8.42/build/Tone.js"></script>
  <style>
    body { font-family: 'Arial', sans-serif; text-align: center; background: #121212; color: #fff; padding: 20px; }
    h1 { color: #1DB954; }
    button { padding: 12px 24px; font-size: 16px; margin: 10px; cursor: pointer; background: #1DB954; color: white; border: none; border-radius: 5px; }
    button:hover { background: #0d8f3e; }
    select { padding: 10px; margin: 10px; font-size: 16px; width: 200px; }
    #output { margin-top: 20px; }
  </style>
</head>
<body>
  <h1>Voice Beat Maker üé§üî•</h1>
  <p>Hum or sing into your mic. We'll turn it into a song!</p>

  <button id="start">üé§ Start Recording (5 sec)</button>
  <button id="stop" disabled>‚èπÔ∏è Stop</button>
  <button id="play" disabled>‚ñ∂Ô∏è Play Generated Song</button>

  <p>
    <label for="genre">Choose Genre:</label>
    <select id="genre">
      <option value="pop">Pop</option>
      <option value="hiphop">Hip-Hop</option>
      <option value="edm">EDM</option>
      <option value="reggae">Reggae</option>
      <option value="rock">Rock</option>
      <option value="jazz">Jazz</option>
      <option value="lofi">Lo-Fi</option>
      <option value="trap">Trap</option>
      <option value="country">Country</option>
      <option value="funk">Funk</option>
    </select>
  </p>

  <div id="output">Status: Ready</div>

  <script>
    let isRecording = false;
    let audioChunks = [];
    let mediaRecorder;
    let audioContext;
    let analyser;
    let source;
    let detectedPitch = 440; // Default A4
    let detectedBPM = 100;
    let buffer;

    const genres = {
      pop: { synth: 'pluck', drum: '8n', chords: ['C4', 'G4', 'Am4', 'F4'], tempo: 120 },
      hiphop: { synth: 'membrane', drum: '4n', chords: ['Dm4', 'G4', 'C4', 'Bb4'], tempo: 85 },
      edm: { synth: 'fm', drum: '16n', chords: ['C3', 'G3', 'A3', 'F3'], tempo: 128 },
      reggae: { synth: 'polySynth', drum: 'off-beat', chords: ['F4', 'Bb4', 'C4', 'Dm4'], tempo: 90 },
      rock: { synth: 'am', drum: '4n', chords: ['E4', 'B4', 'A4', 'C#m4'], tempo: 110 },
      jazz: { synth: 'synth', drum: 'triplet', chords: ['Dm7', 'G7', 'Cmaj7', 'Em7'], tempo: 95 },
      lofi: { synth: 'pluck', drum: 'shuffle', chords: ['Fmaj7', 'Gm7', 'C7', 'Dm7'], tempo: 80 },
      trap: { synth: 'metal', drum: '16n', chords: ['C#m', 'F#m', 'A', 'E'], tempo: 140 },
      country: { synth: 'organ', drum: '2n', chords: ['G4', 'D4', 'Em4', 'C4'], tempo: 100 },
      funk: { synth: 'mono', drum: '16n', chords: ['C3', 'F3', 'G3', 'Eb3'], tempo: 115 }
    };

    document.getElementById('start').onclick = async () => {
      audioChunks = [];
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder = new MediaRecorder(stream);
      audioContext = new (window.AudioContext || window.webkitAudioContext)();
      analyser = audioContext.createAnalyser();
      source = audioContext.createMediaStreamSource(stream);
      source.connect(analyser);

      mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
      mediaRecorder.onstop = onRecordingStop;

      mediaRecorder.start();
      isRecording = true;
      document.getElementById('output').innerText = "üé§ Recording... (5 seconds)";
      document.getElementById('start').disabled = true;
      document.getElementById('stop').disabled = false;

      setTimeout(() => {
        if (isRecording) {
          mediaRecorder.stop();
          stream.getTracks().forEach(track => track.stop());
        }
      }, 5000);
    };

    document.getElementById('stop').onclick = () => {
      if (isRecording && mediaRecorder.state !== "inactive") {
        mediaRecorder.stop();
        const stream = mediaRecorder.stream;
        stream.getTracks().forEach(track => track.stop());
      }
    };

    async function onRecordingStop() {
      isRecording = false;
      const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
      buffer = await audioContext.decodeAudioData(await audioBlob.arrayBuffer());
      document.getElementById('output').innerText = "‚úÖ Recording complete! Click 'Play' to generate song.";
      document.getElementById('start').disabled = false;
      document.getElementById('stop').disabled = true;
      document.getElementById('play').disabled = false;

      // Estimate pitch using autocorrelation
      const channels = buffer.numberOfChannels;
      const length = buffer.length;
      const data = new Float32Array(length);
      for (let i = 0; i < channels; i++) {
        const channelData = buffer.getChannelData(i);
        for (let j = 0; j < length; j++) {
          data[j] += channelData[j];
        }
      }
      for (let i = 0; i < length; i++) data[i] /= channels;

      detectedPitch = estimatePitch(data, audioContext.sampleRate);
      console.log("Estimated pitch:", detectedPitch);
    }

    function estimatePitch(buffer, sampleRate) {
      const SIZE = buffer.length;
      let bestOffset = -1;
      let bestCorrelation = 0;
      let rms = 0;
      let foundGoodCorrelation = false;
      let correlations = new Array(SIZE).fill(0);

      for (let i = 0; i < SIZE; i++) {
        rms += buffer[i] * buffer[i];
      }
      rms = Math.sqrt(rms / SIZE);
      if (rms < 0.01) return -1;

      let lastCorrelation = 1;
      for (let offset = Math.floor(sampleRate / 2000); offset < Math.floor(sampleRate / 50); offset++) {
        let correlation = 0;

        for (let i = 0; i < SIZE; i++) {
          correlation += Math.abs(buffer[i] - buffer[i + offset]);
        }
        correlation = 1 - (correlation / SIZE);
        correlations[offset] = correlation;

        if (correlation > 0.9 && correlation > lastCorrelation) {
          foundGoodCorrelation = true;
          if (correlation > bestCorrelation) {
            bestCorrelation = correlation;
            bestOffset = offset;
          }
        } else if (foundGoodCorrelation) {
          break;
        }
        lastCorrelation = correlation;
      }

      if (bestCorrelation > 0.01) {
        return sampleRate / bestOffset;
      }
      return -1;
    }

    document.getElementById('play').onclick = () => {
      const genreName = document.getElementById('genre').value;
      const genre = genres[genreName];
      Tone.Transport.stop();
      Tone.Transport.bpm.value = genre.tempo;
      const synth = getSynth(genre.synth);

      // Stop any existing sequences
      Tone.Transport.cancel();
      Tone.Transport.dispose();

      // Chord progression
      const chordSeq = new Tone.Sequence((time, chord) => {
        synth.triggerAttackRelease(chord, "2n", time);
      }, genre.chords, "4n").start(0);

      // Drum beat
      const drumSynth = new Tone.MembraneSynth().toDestination();
      const kickPattern = ['C2', null, 'C2', null];
      if (genre.drum === 'off-beat') {
        kickPattern[1] = 'C2';
        kickPattern[3] = 'C2';
      }

      const drumSeq = new Tone.Sequence((time, note) => {
        if (note) {
          drumSynth.triggerAttackRelease(note, "8n", time);
        }
      }, kickPattern, "4n").start(0);

      Tone.Transport.start();
      document.getElementById('output').innerText = `üé∂ Playing ${genreName.toUpperCase()} song in key near ${Math.round(detectedPitch)} Hz!`;
    };

    function getSynth(type) {
      switch (type) {
        case 'fm': return new Tone.FMSynth().toDestination();
        case 'am': return new Tone.AMSynth().toDestination();
        case 'pluck': return new Tone.PluckSynth().toDestination();
        case 'polySynth': return new Tone.PolySynth().toDestination();
        case 'metal': return new Tone.MetalSynth().toDestination();
        case 'organ': return new Tone.AMSynth({ harmonicity: 3 }).toDestination();
        case 'mono': return new Tone.MonoSynth().toDestination();
        default: return new Tone.Synth().toDestination();
      }
    }
  </script>
</body>
</html>
